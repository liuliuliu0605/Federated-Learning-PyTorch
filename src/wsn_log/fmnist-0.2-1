Namespace(cluster_similarity=0.2, data_parallel=False, dataset='fmnist', epochs=600, fake=True, frac=1.0, gpu=0, iid=0, kernel_num=9, kernel_sizes='3,4,5', local_bs=10, local_ep=1, local_rank=None, log_location='../logs/fmnist/complete', lr=0.01, max_pool='True', mix_ep=1, model='lr', momentum=0.5, norm='batch_norm', num_channels=1, num_classes=10, num_clusters=5, num_filters=32, num_users=100, optimizer='sgd', seed=1, stopping_rounds=10, topo='complete', unequal=0, verbose=0)

Experimental details:
    Model     : lr
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 600
    Local Epoches   : 1
    Mix Epoches     : 1

Network details:
    Users       : 100
    Clusters    : 5
    Topology    : complete
    Cluster Similarity : 0.2

Federated parameters:
    Non-IID
    Fraction of users  : 1.0
    Local Batch size   : 10
    Local Epochs       : 1


Topo (p=1.00000):
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
Clusters:  [[1, 4, 9, 10, 13, 17, 19, 20, 52, 54, 60, 61, 64, 66, 68, 71, 76, 82, 89, 98], [6, 7, 31, 33, 34, 35, 36, 39, 40, 43, 44, 55, 59, 62, 69, 70, 78, 92, 93, 99], [11, 14, 21, 25, 26, 30, 46, 49, 53, 58, 65, 72, 74, 79, 81, 85, 87, 90, 91, 96], [0, 8, 16, 22, 27, 29, 32, 41, 45, 47, 48, 57, 67, 73, 77, 83, 84, 86, 88, 97], [2, 3, 5, 12, 15, 18, 23, 24, 28, 37, 38, 42, 50, 51, 56, 63, 75, 80, 94, 95]]

Label distribution in clusters:
-Cluster 0:  [(0, 5009), (1, 5071), (2, 244), (3, 236), (4, 230), (5, 250), (6, 242), (7, 238), (8, 242), (9, 238)]
-Cluster 1:  [(0, 246), (1, 234), (2, 5027), (3, 5053), (4, 255), (5, 225), (6, 232), (7, 248), (8, 240), (9, 240)]
-Cluster 2:  [(0, 248), (1, 232), (2, 251), (3, 229), (4, 5010), (5, 5070), (6, 224), (7, 256), (8, 225), (9, 255)]
-Cluster 3:  [(0, 252), (1, 228), (2, 245), (3, 235), (4, 249), (5, 231), (6, 5065), (7, 5015), (8, 242), (9, 238)]
-Cluster 4:  [(0, 245), (1, 235), (2, 233), (3, 247), (4, 256), (5, 224), (6, 237), (7, 243), (8, 5051), (9, 5029)]
LR(
  (layer): Linear(in_features=784, out_features=10, bias=False)
  (softmax): Softmax(dim=1)
)
num of params:  7840
  0%|          | 0/600 [00:00<?, ?it/s]  0%|          | 0/600 [00:00<?, ?it/s]

 | Global Training Round : 1 |

Remain energy: 5000
Traceback (most recent call last):
  File "wsn_pfl_main.py", line 189, in <module>
    train_loss = fake_rs['train_loss'][epoch]
NameError: name 'fake_rs' is not defined
