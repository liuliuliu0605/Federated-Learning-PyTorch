Namespace(cluster_similarity=0.8, data_parallel=False, dataset='fmnist', epochs=200, fake=False, frac=1.0, gpu=0, iid=0, kernel_num=9, kernel_sizes='3,4,5', local_bs=10, local_ep=1, local_iter=10, local_rank=None, log_location='../logs', lr=0.01, max_pool='True', mix_ep=2, model='lr', momentum=0.5, norm='batch_norm', num_channels=1, num_classes=10, num_clusters=5, num_filters=32, num_users=100, optimizer='sgd', seed=10, stopping_rounds=10, topo='complete', unequal=0, verbose=0)

Federated parameters:
    Model     : lr
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 200
    Local Iterations   : 10
    Mix cycles     : 2
    Non-IID
    Fraction of users  : 1.0
    Local Batch size   : 10

Network details:
    Users       : 100
    Clusters    : 5
    Topology    : complete
    Cluster Similarity : 0.8


Topo (p=1.00000):
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200

Label distribution in clusters:
-Cluster 0:  [(0, 2163), (1, 2157), (2, 987), (3, 933), (4, 1000), (5, 920), (6, 954), (7, 966), (8, 936), (9, 984)]
-Cluster 1:  [(0, 991), (1, 929), (2, 2161), (3, 2159), (4, 970), (5, 950), (6, 950), (7, 970), (8, 982), (9, 938)]
-Cluster 2:  [(0, 944), (1, 976), (2, 933), (3, 987), (4, 2129), (5, 2191), (6, 968), (7, 952), (8, 995), (9, 925)]
-Cluster 3:  [(0, 958), (1, 962), (2, 969), (3, 951), (4, 965), (5, 955), (6, 2172), (7, 2148), (8, 956), (9, 964)]
-Cluster 4:  [(0, 944), (1, 976), (2, 950), (3, 970), (4, 936), (5, 984), (6, 956), (7, 964), (8, 2131), (9, 2189)]
num of params:  7840
  0%|          | 0/200 [00:00<?, ?it/s]/data/magnolia/Federated-Learning-PyTorch/src/update.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(image), torch.tensor(label)
  0%|          | 1/200 [00:05<19:43,  5.95s/it]  1%|          | 2/200 [00:12<21:32,  6.53s/it]  2%|▏         | 3/200 [00:19<21:40,  6.60s/it]  2%|▏         | 4/200 [00:26<21:42,  6.65s/it]  2%|▎         | 5/200 [00:33<21:54,  6.74s/it]  3%|▎         | 6/200 [00:40<22:24,  6.93s/it]  4%|▎         | 7/200 [00:47<22:29,  6.99s/it]  4%|▍         | 8/200 [00:54<22:26,  7.01s/it]  4%|▍         | 9/200 [01:01<22:24,  7.04s/it]  5%|▌         | 10/200 [01:08<22:17,  7.04s/it]  6%|▌         | 11/200 [01:15<22:11,  7.04s/it]  6%|▌         | 12/200 [01:22<22:00,  7.02s/it]  6%|▋         | 13/200 [01:30<22:01,  7.07s/it]  7%|▋         | 14/200 [01:37<22:20,  7.21s/it]  8%|▊         | 15/200 [01:45<22:28,  7.29s/it]  8%|▊         | 16/200 [01:52<22:24,  7.31s/it]  8%|▊         | 17/200 [01:59<22:09,  7.26s/it]  9%|▉         | 18/200 [02:06<22:09,  7.30s/it] 10%|▉         | 19/200 [02:14<21:53,  7.26s/it] 10%|█         | 20/200 [02:21<21:46,  7.26s/it] 10%|█         | 21/200 [02:28<21:32,  7.22s/it] 11%|█         | 22/200 [02:35<21:29,  7.25s/it]