Namespace(cluster_similarity=0.8, data_parallel=False, dataset='fmnist', epochs=200, fake=False, frac=1.0, gpu=0, iid=0, kernel_num=9, kernel_sizes='3,4,5', local_bs=10, local_ep=1, local_iter=10, local_rank=None, log_location='../logs', lr=0.01, max_pool='True', mix_ep=5, model='lr', momentum=0.5, norm='batch_norm', num_channels=1, num_classes=10, num_clusters=5, num_filters=32, num_users=100, optimizer='sgd', seed=10, stopping_rounds=10, topo='complete', unequal=0, verbose=0)

Federated parameters:
    Model     : lr
    Optimizer : sgd
    Learning  : 0.01
    Global Rounds   : 200
    Local Iterations   : 10
    Mix cycles     : 5
    Non-IID
    Fraction of users  : 1.0
    Local Batch size   : 10

Network details:
    Users       : 100
    Clusters    : 5
    Topology    : complete
    Cluster Similarity : 0.8


Topo (p=1.00000):
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200
0.200,0.200,0.200,0.200,0.200

Label distribution in clusters:
-Cluster 0:  [(0, 2163), (1, 2157), (2, 987), (3, 933), (4, 1000), (5, 920), (6, 954), (7, 966), (8, 936), (9, 984)]
-Cluster 1:  [(0, 991), (1, 929), (2, 2161), (3, 2159), (4, 970), (5, 950), (6, 950), (7, 970), (8, 982), (9, 938)]
-Cluster 2:  [(0, 944), (1, 976), (2, 933), (3, 987), (4, 2129), (5, 2191), (6, 968), (7, 952), (8, 995), (9, 925)]
-Cluster 3:  [(0, 958), (1, 962), (2, 969), (3, 951), (4, 965), (5, 955), (6, 2172), (7, 2148), (8, 956), (9, 964)]
-Cluster 4:  [(0, 944), (1, 976), (2, 950), (3, 970), (4, 936), (5, 984), (6, 956), (7, 964), (8, 2131), (9, 2189)]
num of params:  7840
  0%|          | 0/200 [00:00<?, ?it/s]/data/magnolia/Federated-Learning-PyTorch/src/update.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(image), torch.tensor(label)
  0%|          | 1/200 [00:06<21:13,  6.40s/it]  1%|          | 2/200 [00:14<23:28,  7.11s/it]  2%|▏         | 3/200 [00:20<22:50,  6.96s/it]  2%|▏         | 4/200 [00:27<22:38,  6.93s/it]  2%|▎         | 5/200 [00:34<22:45,  7.00s/it]  3%|▎         | 6/200 [00:41<22:20,  6.91s/it]  4%|▎         | 7/200 [00:48<22:23,  6.96s/it]  4%|▍         | 8/200 [00:55<22:13,  6.95s/it]  4%|▍         | 9/200 [01:02<22:08,  6.96s/it]  5%|▌         | 10/200 [01:09<22:19,  7.05s/it]  6%|▌         | 11/200 [01:16<22:05,  7.01s/it]  6%|▌         | 12/200 [01:23<21:54,  6.99s/it]  6%|▋         | 13/200 [01:30<21:45,  6.98s/it]  7%|▋         | 14/200 [01:37<21:34,  6.96s/it]  8%|▊         | 15/200 [01:44<21:32,  6.99s/it]  8%|▊         | 16/200 [01:51<21:16,  6.94s/it]  8%|▊         | 17/200 [01:58<21:13,  6.96s/it]  9%|▉         | 18/200 [02:05<21:07,  6.96s/it] 10%|▉         | 19/200 [02:12<20:50,  6.91s/it] 10%|█         | 20/200 [02:19<20:43,  6.91s/it] 10%|█         | 21/200 [02:25<20:38,  6.92s/it]